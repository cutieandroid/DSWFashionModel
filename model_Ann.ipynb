{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8UVKPPBguyMa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "historic_data = pd.read_csv('historic.csv')"
      ],
      "metadata": {
        "id": "e16IFuzdu2gl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historic_data.drop(['item_no'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "NarXsWSZu558"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historic_data = pd.get_dummies(historic_data, columns=['category', 'main_promotion', 'color'])\n",
        "\n"
      ],
      "metadata": {
        "id": "yfsmBDqDu8O4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "historic_data['success_indicator'] = label_encoder.fit_transform(historic_data['success_indicator'])\n"
      ],
      "metadata": {
        "id": "S5M_0AG5xSAu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tfFR8D-WxmE3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = historic_data.drop('success_indicator', axis=1)\n",
        "y = historic_data['success_indicator']"
      ],
      "metadata": {
        "id": "5xJiFwq3u-eI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "uhecwHWFvAt2"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "l_yZduFmvDCp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "K9VdwqSIvFYE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "eAlf2B49vHok"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tn8zvCHCv05H",
        "outputId": "24eab1fa-0618-4e3c-eb20-c0a7d56b5521"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "200/200 [==============================] - 1s 2ms/step - loss: 0.4916 - accuracy: 0.7878\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8466\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8517\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.4047 - accuracy: 0.8523\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3995 - accuracy: 0.8555\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3979 - accuracy: 0.8548\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3944 - accuracy: 0.8564\n",
            "Epoch 8/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3907 - accuracy: 0.8573\n",
            "Epoch 9/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3906 - accuracy: 0.8567\n",
            "Epoch 10/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3892 - accuracy: 0.8592\n",
            "Epoch 11/50\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.3875 - accuracy: 0.8584\n",
            "Epoch 12/50\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.3860 - accuracy: 0.8589\n",
            "Epoch 13/50\n",
            "200/200 [==============================] - 1s 7ms/step - loss: 0.3850 - accuracy: 0.8602\n",
            "Epoch 14/50\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.3821 - accuracy: 0.8606\n",
            "Epoch 15/50\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.3828 - accuracy: 0.8598\n",
            "Epoch 16/50\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.3812 - accuracy: 0.8602\n",
            "Epoch 17/50\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.3793 - accuracy: 0.8612\n",
            "Epoch 18/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3801 - accuracy: 0.8609\n",
            "Epoch 19/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3787 - accuracy: 0.8633\n",
            "Epoch 20/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3780 - accuracy: 0.8627\n",
            "Epoch 21/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3766 - accuracy: 0.8619\n",
            "Epoch 22/50\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.3759 - accuracy: 0.8606\n",
            "Epoch 23/50\n",
            "200/200 [==============================] - 1s 5ms/step - loss: 0.3760 - accuracy: 0.8612\n",
            "Epoch 24/50\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3747 - accuracy: 0.8606\n",
            "Epoch 25/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8630\n",
            "Epoch 26/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3737 - accuracy: 0.8630\n",
            "Epoch 27/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3726 - accuracy: 0.8622\n",
            "Epoch 28/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8611\n",
            "Epoch 29/50\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3715 - accuracy: 0.8614\n",
            "Epoch 30/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8619\n",
            "Epoch 31/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8622\n",
            "Epoch 32/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3711 - accuracy: 0.8641\n",
            "Epoch 33/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3692 - accuracy: 0.8628\n",
            "Epoch 34/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8614\n",
            "Epoch 35/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8628\n",
            "Epoch 36/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.8625\n",
            "Epoch 37/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3676 - accuracy: 0.8648\n",
            "Epoch 38/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3674 - accuracy: 0.8641\n",
            "Epoch 39/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8627\n",
            "Epoch 40/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8633\n",
            "Epoch 41/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8633\n",
            "Epoch 42/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8639\n",
            "Epoch 43/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8644\n",
            "Epoch 44/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3646 - accuracy: 0.8634\n",
            "Epoch 45/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8636\n",
            "Epoch 46/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8636\n",
            "Epoch 47/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8662\n",
            "Epoch 48/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8627\n",
            "Epoch 49/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3620 - accuracy: 0.8642\n",
            "Epoch 50/50\n",
            "200/200 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8631\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a900766c700>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLXXlz9zv3MO",
        "outputId": "6e2820d3-1448-440d-f0e6-52324d98881f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.8462\n",
            "Test Loss: 0.4253\n",
            "Test Accuracy: 0.8462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For logistic regression we got accuracy as 81 percent for svm we got accuracy as 84 percent for random forest we got accuracy as 82 percent and for gradient boosting model we got accuray as 83.5 percent and for  a Artificial neural netwrk model we got accuracy between 85 and 87 percent"
      ],
      "metadata": {
        "id": "299KOaXAbHOs"
      }
    }
  ]
}